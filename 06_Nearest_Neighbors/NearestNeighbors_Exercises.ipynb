{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Nearest Neighbors Exercises",
   "metadata": {
    "colab_type": "text",
    "id": "3hHvV20eD58o",
    "cell_id": "00000-c2e7636f-01eb-4539-9615-f462e6f2f682",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 82
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "z1h_AAj_D4kX",
    "colab": {},
    "cell_id": "00001-f904f2ff-f49d-4cf5-a2bf-8f8d4d09a9f4",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ab7040a7",
    "execution_start": 1657810209351,
    "execution_millis": 1738,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 189
   },
   "source": "import numpy as np\nimport pandas as po\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Problem 1\n\nConsider the following simple data-set:\n\n<img src=\"https://github.com/BeaverWorksMedlytics2020/Data_Public/raw/master/Images/Week1/knn_notebook_example_table.png\" alt=\"Example Table\" width=\"600\">\n\nNow consider the Sample:\n    $$X= 4, Y = 4, Z = 2$$",
   "metadata": {
    "id": "87tmgzNMb9tV",
    "colab_type": "text",
    "cell_id": "00002-2beb2222-d4f3-4315-93f0-65c78469f97c",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 429.90625
   }
  },
  {
   "cell_type": "markdown",
   "source": "Using kNN, what is the class for this sample for $k = 1$ and $k = 3?$ Use the Eucledian metric.\n\n(YOUR ANSWER HERE)\n\nDistance to 1: sqrt(2)\nDistance to 2: sqrt(13)\nDistance to 3: sqrt(14)\n\nIf k = 1: Class 1\nIf k = 3: Class 2",
   "metadata": {
    "colab_type": "text",
    "id": "gqjait37Qws0",
    "cell_id": "00003-18cde72a-8ca0-4c0d-b013-47e1989dbbb6",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 161.59375
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Problem 2\nEarlier in the tutorial we were told that kNN depends on several factors, one of them being $k$. Consider the following datasets below, find the optimal value of $k$ that gives the highest accuracy. Visualize your data! Can you come up with some rule for getting a good idea of what $k$ is? \n\nHINT: look for a pattern/bound! Answer should be in terms of the size of the dataset $n$. ",
   "metadata": {
    "colab_type": "text",
    "id": "MtE0uiKuTWsI",
    "cell_id": "00004-1e5b3c66-acca-4989-9b28-d291cabf73b5",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 189.59375
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aapncOgUo_5r",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00005-5ace4d9e-53cb-4a41-984a-68dc97516054",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "54703dfb",
    "execution_start": 1657810211089,
    "execution_millis": 9476,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1664.1875,
    "deepnote_output_heights": [
     null,
     21.1875,
     250
    ]
   },
   "source": "# Solve this problem for each of these datasets\nfrom sklearn.datasets import load_iris \nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.datasets import load_wine \n\n# Load those datasets into some easily accessible variables\n# The datasets are already normalized, so that saves us some steps!\niris = load_iris()                    #iris dataset: size = 150\nbreast_cancer = load_breast_cancer()  #diabetes dataset: size = 569\nwine = load_wine()                    #wine dataset: size 178\n\n# This function will perfom KNN classification for a specified k\ndef split_train_test_dataset(dataset, k, test_size=0.2):\n    \"\"\"Loads and performs KNN classification on the provided dataset\"\"\"\n    # Grab and split the dataset\n    X_train, X_val, y_train, y_val = train_test_split(\n        dataset.data, dataset.target, test_size=test_size, random_state=0)\n\n    # Build a KNN classifier, fit it and test its predictions\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    print(\"Validation Accuracy is {:5.1%}\".format(\n        accuracy_score(y_val, knn.predict(X_val))))\n    return accuracy_score(y_val, knn.predict(X_val))\n\nk = 1\nk_arr = []\nacc_arr = []\n\nfor i in range(455):\n    acc_arr.append( split_train_test_dataset(breast_cancer, k, test_size=0.2) )\n    k_arr.append(k)\n    k = k+1\n\nplt.plot(k_arr, acc_arr, \"r-\")\n",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Validation Accuracy is 91.2%\nValidation Accuracy is 89.5%\nValidation Accuracy is 91.2%\nValidation Accuracy is 92.1%\nValidation Accuracy is 93.9%\nValidation Accuracy is 93.9%\nValidation Accuracy is 94.7%\nValidation Accuracy is 94.7%\nValidation Accuracy is 96.5%\nValidation Accuracy is 94.7%\nValidation Accuracy is 96.5%\nValidation Accuracy is 96.5%\nValidation Accuracy is 96.5%\nValidation Accuracy is 96.5%\nValidation Accuracy is 96.5%\nValidation Accuracy is 96.5%\nValidation Accuracy is 96.5%\nValidation Accuracy is 96.5%\nValidation Accuracy is 96.5%\nValidation Accuracy is 96.5%\nValidation Accuracy is 96.5%\nValidation Accuracy is 96.5%\nValidation Accuracy is 96.5%\nValidation Accuracy is 96.5%\nValidation Accuracy is 96.5%\nValidation Accuracy is 96.5%\nValidation Accuracy is 95.6%\nValidation Accuracy is 96.5%\nValidation Accuracy is 95.6%\nValidation Accuracy is 96.5%\nValidation Accuracy is 94.7%\nValidation Accuracy is 94.7%\nValidation Accuracy is 94.7%\nValidation Accuracy is 94.7%\nValidation Accuracy is 94.7%\nValidation Accuracy is 94.7%\nValidation Accuracy is 94.7%\nValidation Accuracy is 95.6%\nValidation Accuracy is 94.7%\nValidation Accuracy is 95.6%\nValidation Accuracy is 94.7%\nValidation Accuracy is 95.6%\nValidation Accuracy is 95.6%\nValidation Accuracy is 95.6%\nValidation Accuracy is 94.7%\nValidation Accuracy is 94.7%\nValidation Accuracy is 94.7%\nValidation Accuracy is 94.7%\nValidation Accuracy is 94.7%\nValidation Accuracy is 94.7%\nValidation Accuracy is 94.7%\nValidation Accuracy is 94.7%\nValidation Accuracy is 94.7%\nValidation Accuracy is 94.7%\nValidation Accuracy is 93.9%\nValidation Accuracy is 94.7%\nValidation Accuracy is 93.9%\nValidation Accuracy is 93.9%\nValidation Accuracy is 93.9%\nValidation Accuracy is 93.9%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 92.1%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 93.0%\nValidation Accuracy is 92.1%\nValidation Accuracy is 92.1%\nValidation Accuracy is 92.1%\nValidation Accuracy is 92.1%\nValidation Accuracy is 91.2%\nValidation Accuracy is 92.1%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 90.4%\nValidation Accuracy is 89.5%\nValidation Accuracy is 90.4%\nValidation Accuracy is 89.5%\nValidation Accuracy is 89.5%\nValidation Accuracy is 89.5%\nValidation Accuracy is 89.5%\nValidation Accuracy is 89.5%\nValidation Accuracy is 89.5%\nValidation Accuracy is 89.5%\nValidation Accuracy is 89.5%\nValidation Accuracy is 89.5%\nValidation Accuracy is 89.5%\nValidation Accuracy is 89.5%\nValidation Accuracy is 89.5%\nValidation Accuracy is 89.5%\nValidation Accuracy is 89.5%\nValidation Accuracy is 89.5%\nValidation Accuracy is 89.5%\nValidation Accuracy is 89.5%\nValidation Accuracy is 89.5%\nValidation Accuracy is 89.5%\nValidation Accuracy is 89.5%\nValidation Accuracy is 89.5%\nValidation Accuracy is 89.5%\nValidation Accuracy is 88.6%\nValidation Accuracy is 89.5%\nValidation Accuracy is 88.6%\nValidation Accuracy is 88.6%\nValidation Accuracy is 88.6%\nValidation Accuracy is 88.6%\nValidation Accuracy is 88.6%\nValidation Accuracy is 88.6%\nValidation Accuracy is 88.6%\nValidation Accuracy is 88.6%\nValidation Accuracy is 87.7%\nValidation Accuracy is 87.7%\nValidation Accuracy is 87.7%\nValidation Accuracy is 87.7%\nValidation Accuracy is 87.7%\nValidation Accuracy is 87.7%\nValidation Accuracy is 87.7%\nValidation Accuracy is 87.7%\nValidation Accuracy is 87.7%\nValidation Accuracy is 87.7%\nValidation Accuracy is 86.8%\nValidation Accuracy is 86.8%\nValidation Accuracy is 86.8%\nValidation Accuracy is 86.8%\nValidation Accuracy is 85.1%\nValidation Accuracy is 85.1%\nValidation Accuracy is 85.1%\nValidation Accuracy is 85.1%\nValidation Accuracy is 86.0%\nValidation Accuracy is 86.0%\nValidation Accuracy is 86.0%\nValidation Accuracy is 86.0%\nValidation Accuracy is 86.0%\nValidation Accuracy is 86.0%\nValidation Accuracy is 86.0%\nValidation Accuracy is 86.0%\nValidation Accuracy is 86.0%\nValidation Accuracy is 86.0%\nValidation Accuracy is 85.1%\nValidation Accuracy is 85.1%\nValidation Accuracy is 85.1%\nValidation Accuracy is 85.1%\nValidation Accuracy is 85.1%\nValidation Accuracy is 85.1%\nValidation Accuracy is 85.1%\nValidation Accuracy is 85.1%\nValidation Accuracy is 85.1%\nValidation Accuracy is 85.1%\nValidation Accuracy is 85.1%\nValidation Accuracy is 85.1%\nValidation Accuracy is 85.1%\nValidation Accuracy is 85.1%\nValidation Accuracy is 85.1%\nValidation Accuracy is 85.1%\nValidation Accuracy is 85.1%\nValidation Accuracy is 85.1%\nValidation Accuracy is 84.2%\nValidation Accuracy is 84.2%\nValidation Accuracy is 84.2%\nValidation Accuracy is 84.2%\nValidation Accuracy is 84.2%\nValidation Accuracy is 84.2%\nValidation Accuracy is 83.3%\nValidation Accuracy is 83.3%\nValidation Accuracy is 83.3%\nValidation Accuracy is 83.3%\nValidation Accuracy is 82.5%\nValidation Accuracy is 82.5%\nValidation Accuracy is 82.5%\nValidation Accuracy is 82.5%\nValidation Accuracy is 82.5%\nValidation Accuracy is 82.5%\nValidation Accuracy is 82.5%\nValidation Accuracy is 82.5%\nValidation Accuracy is 82.5%\nValidation Accuracy is 82.5%\nValidation Accuracy is 82.5%\nValidation Accuracy is 82.5%\nValidation Accuracy is 82.5%\nValidation Accuracy is 82.5%\nValidation Accuracy is 82.5%\nValidation Accuracy is 82.5%\nValidation Accuracy is 82.5%\nValidation Accuracy is 82.5%\nValidation Accuracy is 82.5%\nValidation Accuracy is 82.5%\nValidation Accuracy is 81.6%\nValidation Accuracy is 81.6%\nValidation Accuracy is 81.6%\nValidation Accuracy is 81.6%\nValidation Accuracy is 81.6%\nValidation Accuracy is 81.6%\nValidation Accuracy is 80.7%\nValidation Accuracy is 81.6%\nValidation Accuracy is 81.6%\nValidation Accuracy is 81.6%\nValidation Accuracy is 80.7%\nValidation Accuracy is 80.7%\nValidation Accuracy is 80.7%\nValidation Accuracy is 80.7%\nValidation Accuracy is 80.7%\nValidation Accuracy is 80.7%\nValidation Accuracy is 80.7%\nValidation Accuracy is 80.7%\nValidation Accuracy is 80.7%\nValidation Accuracy is 80.7%\nValidation Accuracy is 80.7%\nValidation Accuracy is 80.7%\nValidation Accuracy is 80.7%\nValidation Accuracy is 80.7%\nValidation Accuracy is 80.7%\nValidation Accuracy is 80.7%\nValidation Accuracy is 79.8%\nValidation Accuracy is 79.8%\nValidation Accuracy is 79.8%\nValidation Accuracy is 79.8%\nValidation Accuracy is 79.8%\nValidation Accuracy is 79.8%\nValidation Accuracy is 79.8%\nValidation Accuracy is 79.8%\nValidation Accuracy is 79.8%\nValidation Accuracy is 79.8%\nValidation Accuracy is 79.8%\nValidation Accuracy is 79.8%\nValidation Accuracy is 78.9%\nValidation Accuracy is 78.9%\nValidation Accuracy is 78.9%\nValidation Accuracy is 78.9%\nValidation Accuracy is 78.1%\nValidation Accuracy is 78.1%\nValidation Accuracy is 77.2%\nValidation Accuracy is 77.2%\nValidation Accuracy is 75.4%\nValidation Accuracy is 75.4%\nValidation Accuracy is 74.6%\nValidation Accuracy is 74.6%\nValidation Accuracy is 74.6%\nValidation Accuracy is 74.6%\nValidation Accuracy is 73.7%\nValidation Accuracy is 73.7%\nValidation Accuracy is 69.3%\nValidation Accuracy is 69.3%\nValidation Accuracy is 69.3%\nValidation Accuracy is 69.3%\nValidation Accuracy is 68.4%\nValidation Accuracy is 68.4%\nValidation Accuracy is 67.5%\nValidation Accuracy is 68.4%\nValidation Accuracy is 66.7%\nValidation Accuracy is 66.7%\nValidation Accuracy is 66.7%\nValidation Accuracy is 66.7%\nValidation Accuracy is 65.8%\nValidation Accuracy is 65.8%\nValidation Accuracy is 65.8%\nValidation Accuracy is 65.8%\nValidation Accuracy is 64.0%\nValidation Accuracy is 64.0%\nValidation Accuracy is 64.0%\nValidation Accuracy is 64.0%\nValidation Accuracy is 64.0%\nValidation Accuracy is 64.0%\nValidation Accuracy is 63.2%\nValidation Accuracy is 63.2%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\nValidation Accuracy is 58.8%\n",
     "output_type": "stream"
    },
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x7f1b6bf2ab20>]"
     },
     "metadata": {}
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light",
      "image/png": {
       "width": 378,
       "height": 248
      }
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lQk-b90Kgz-S",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00006-e64c614d-ef64-4987-be50-dc0a108ff803",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d1e2b9e9",
    "execution_start": 1657810220213,
    "execution_millis": 0,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 153
   },
   "source": "# YOUR CODE HERE\n\n# Iris: (150, 5-25)\n# Breast_Cancer: (569, 10-30)\n# Wine: (178, )",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Write a single mathematical expression describing the relationship you found between $n$ (the size of the dataset) and $k$ (the number of datapoints used to classify each validation datum).",
   "metadata": {
    "id": "n1_EbFlqzjAT",
    "colab_type": "text",
    "cell_id": "00007-9e31e134-f849-45d6-980b-81094c4e074f",
    "owner_user_id": "5006719d-0afd-4aec-a81f-346afe7a90f3",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 74.796875
   }
  },
  {
   "cell_type": "markdown",
   "source": "(YOUR ANSWER HERE)",
   "metadata": {
    "id": "PbbrX6rGq6CV",
    "colab_type": "text",
    "cell_id": "00008-01630e1e-58e1-480d-b182-928216e4dc1d",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Problem 3\nNow, we will **be writing our k-NNA**. Recall that we said a kNN is comprised of a predictions and using those predictions to classify the data. Here we will try to mimic sklearn's kNN methods. We will be using the Pima diabetes dataset. ",
   "metadata": {
    "colab_type": "text",
    "id": "-vDZy0F3eyeH",
    "cell_id": "00009-6b713464-0106-4edd-946f-132b72febf84",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 130.796875
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Loading and splitting data",
   "metadata": {
    "id": "8YFfjG9G3lVO",
    "colab_type": "text",
    "cell_id": "00010-84a30058-7b6a-4895-b6d3-3c2289005067",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 62
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "zbs8WICFgITd",
    "colab": {},
    "cell_id": "00011-1c057c97-58b6-4874-80b7-10c7451fa29c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ac1b2bb9",
    "execution_start": 1657810220214,
    "execution_millis": 270,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 261
   },
   "source": "url = \"https://github.com/BeaverWorksMedlytics2020/Data_Public/raw/master/NotebookExampleData/Week1/diabetes.csv\"\nnames = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\ndata = po.read_csv(url, names=names)\n\n# Dropping NaN rows\ninvalid = ['plas', 'pres', 'skin', 'test', 'mass']\n\nfor i in invalid:\n    data[i].replace(to_replace=0, value=np.nan, inplace=True)\n    \ndata = data.dropna(axis=0).reset_index(drop=True)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Now, let's clearly define which columns will act as explanatory variables, and which column will be the target value, and split the dataset between your training data and testing data. Let's try an 80-20 split and use sklearn's [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) method (set random_state = 0 so we get the same output each time).",
   "metadata": {
    "id": "aSUwHL6-4P2F",
    "colab_type": "text",
    "cell_id": "00012-edbb2bcc-a36e-4f35-82dc-f76f34842e05",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 97.1875
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "9MXZjxRcgy78",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "outputId": "91bb35f5-9c29-4c6b-dbba-7a0644a3e2ca",
    "cell_id": "00013-92ad0b5c-3054-4097-b3ae-6285d5b03669",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d98a6cd6",
    "execution_start": 1657810220484,
    "execution_millis": 104,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 421.078125
   },
   "source": "# Columns we will use to make predictions with (features!) feel free to play around with these\nX_cols = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age']\n\n# Column that we want to predict (the labels)\ny_col = 'class'\n\n# 80-20 train-test split of datset\ntest_size = 0.2\nX_train, X_test, y_train, y_test = train_test_split(data[X_cols], data[y_col], test_size=test_size, random_state=0)\n\n# Further split X and y of training into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=test_size, random_state=0)\n\nprint('There are {} training samples with {} features and {} associated classification labels'.format(*X_train.shape, *y_train.shape))\nprint('There are {} validation samples with {} features and {} associated classification labels'.format(*X_val.shape, *y_val.shape))\nprint('There are {} test samples with {} features and {} associated classification labels'.format(*X_test.shape, *y_test.shape))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "There are 250 training samples with 8 features and 250 associated classification labels\nThere are 63 validation samples with 8 features and 63 associated classification labels\nThere are 79 test samples with 8 features and 79 associated classification labels\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Normalizing Data\n\nLet's not forget to normalize the data! We'll use sklearn's StandardScaler normalization like we did before to normalize the training **and** validation/data.",
   "metadata": {
    "colab_type": "text",
    "id": "De_EJnYKgz_6",
    "cell_id": "00014-d3d19f71-9aab-4cb2-a5bc-bd51c048aaab",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 122.796875
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "6PD6-ibriBJO",
    "colab": {},
    "cell_id": "00015-3c4b33fb-bf48-4a47-888f-26f963243ca1",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "844e8ff7",
    "execution_start": 1657810220486,
    "execution_millis": 8,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 387
   },
   "source": "from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nfor i in list(X_train):\n    feature_data_train = X_train[i].values.reshape(-1, 1)\n    scaler.fit(feature_data_train)\n    X_train[i] = scaler.transform(feature_data_train)\n\nfor j in list(X_test):\n    feature_data_test = X_test[j].values.reshape(-1, 1)\n    scaler.fit(feature_data_test)\n    X_test[j] = scaler.transform(feature_data_test)\n    \nfor k in list(X_val):\n    feature_data_val = X_val[k].values.reshape(-1, 1)\n    scaler.fit(feature_data_val)\n    X_val[k] = scaler.transform(feature_data_val)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Writing your kNN\n\nNow for the fun part! Fill in the 3 following methods, euclidean_dist(), predict(), and knn().\n\nThe predict method that we'll make below needs to: \n1. Compute the euclidean distance between the “new” observation and all the data points in the training set. \n2. Assign the corresponding label to the observation\n3. Select the k nearest ones and perform a \"majority vote\"",
   "metadata": {
    "colab_type": "text",
    "id": "hnv61aiiitxU",
    "cell_id": "00016-936a23e0-5940-4cd3-bfbf-f65294228af4",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 237.984375
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xXkIw6zN3lVb",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00017-14b68561-0190-4b35-9b04-3b33196a69b9",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d7861c43",
    "execution_start": 1657810220494,
    "execution_millis": 21,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 315
   },
   "source": "# Euclidean distance function from tutorial\ndef euclidean_dist(datum1, datum2):\n    inner_val = 0.0\n\n    for g in range(datum1.shape[0]):\n        # print(datum1)\n        # print(datum2)\n        #print(\"------\")\n        inner_val += (datum1[g]- datum2[g]) ** 2\n    \n    distance = np.sqrt(inner_val)\n    return(distance)\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "FqJkm_ytjFgM",
    "colab": {},
    "cell_id": "00018-7a3be6d5-55b3-4735-9047-9e5f47a66054",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "15b83aa3",
    "execution_start": 1657810840470,
    "execution_millis": 393,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 928.1875,
    "deepnote_output_heights": [
     21.1875
    ]
   },
   "source": "from collections import Counter\n\ndef predict(x_training, y_training, x_test_sample, k):\n    \n    \n    # Create list for distances and targets\n    distances = []\n    targets = []\n\n    #print(x_test_sample)\n    \n    for i in range(x_training.shape[0]):\n        transposed = np.transpose(x_training.iloc[i])\n        distances.append(euclidean_dist(transposed, x_test_sample))\n        targets.append( y_training.iloc[i] )\n        #print ( x_training.loc[i])\n    \n    nearest = []\n    classes = []\n\n    for i in range(k):\n        minimum = distances[0]\n        targetclass = targets[0]\n\n        for j in range(len(distances)):\n            if(distances[j]<minimum):\n                minimum = distances[j]\n                targetclass = targets[j]\n        \n        # remove object or index?\n        nearest.append (distances.remove(minimum) )\n        classes.append(targetclass)\n    \n    max_count = 0\n    majority = 0\n    for t in classes:\n        count = classes.count(t)\n        if (count>max_count):\n            max_count = count\n            majority = t\n    \n    return majority\n    \n\npredict(X_train, y_train, X_val.iloc[0], k=5)\n",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 18,
     "data": {
      "text/plain": "0"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BguZLcRa3lVh",
    "colab_type": "code",
    "colab": {},
    "cell_id": "00019-0630ca1e-0300-4f0e-8a92-1b703be12bbe",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "319d4e53",
    "execution_start": 1657810939417,
    "execution_millis": 2868,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 852,
    "deepnote_output_heights": [
     611
    ]
   },
   "source": "def knn(x_training, y_training, x_testing, k):\n    y_pred = []\n\n    for i in range(len(x_testing)):\n        y_pred.append(predict(x_training, y_training, np.array(x_testing.iloc[i]),k))\n    # YOUR CODE HERE\n    return y_pred\n\nknn(X_train, y_train, X_val, k=5)",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 23,
     "data": {
      "text/plain": "[0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0]"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "When done, test your code by running the methods here!",
   "metadata": {
    "colab_type": "text",
    "id": "4uhQZPIpjdo9",
    "cell_id": "00020-cfffd903-553f-4ecc-8220-5636a082d81a",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "AHRJXVr7jcao",
    "colab": {},
    "cell_id": "00021-89b4af94-0959-47b8-ac7a-1c2f48e40679",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "411446fa",
    "execution_start": 1657810954337,
    "execution_millis": 2502,
    "owner_user_id": "c4be1506-04b7-4de0-bca3-1f448f666af7",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 257.390625
   },
   "source": "from sklearn.metrics import accuracy_score\nimport time\n\nstart = time.time()\npredictions_slow = knn(X_train, y_train, X_val, k=5)\n\nprint('Took {} seconds'.format(time.time() - start))\nprint(\"Validation Accuracy is \", accuracy_score(y_val,predictions_slow)*100)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Took 2.202967882156372 seconds\nValidation Accuracy is  71.42857142857143\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "Check sklearn's predictions on validation data from the tutorial notebook and make sure they match yours. Sklearn is faster, but you should get the same answers.",
   "metadata": {
    "id": "2a51RcbJ3lVq",
    "colab_type": "text",
    "cell_id": "00022-4a85eefc-cd74-4a60-894d-aa845d36111f",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 74.796875
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=937aabd8-b755-4949-a91c-305bf1afbf2a' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "NearestNeighbors_Exercises",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "deepnote_notebook_id": "9b6a0168-bffb-4750-b7a9-565c6addf8e5",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}